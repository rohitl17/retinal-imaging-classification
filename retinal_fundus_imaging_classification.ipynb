{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dV4GCHKVpWH"
   },
   "source": [
    "# Step 0: Exploratory Data Analysis\n",
    "\n",
    "Explore the data and share your insights!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UEFKaXkbVpWI"
   },
   "outputs": [],
   "source": [
    "# Importing Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "from keras.layers import Dense, Input, Conv2D, Conv2DTranspose, Flatten, Reshape\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import glob, random\n",
    "\n",
    "import numpy as np\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler,ReduceLROnPlateau,CSVLogger,ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score,roc_auc_score\n",
    "from sklearn.metrics import cohen_kappa_score,classification_report,auc,roc_curve\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iytAt5DfVpWM"
   },
   "source": [
    "### Define the paths for the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WGBZX-bJYhWj",
    "outputId": "000410e8-9765-4a56-d5f3-1b2771155f3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "# Since the work for this take home challenge is dine Google Colab, mounting google drive here\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hEFzI4weVpWN"
   },
   "outputs": [],
   "source": [
    "data_path=pathlib.Path(\"/content/gdrive/My Drive/Colab Data/Data/\")\n",
    "# data_path = pathlib.Path(\"Data\") \n",
    "image_path = data_path/  'fundus_images'\n",
    "simple_model_subset_path = data_path/ 'simple_model_subset.csv'\n",
    "cnn_subset_path = data_path/ 'cnn_subset.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVgNA4k5VpWO"
   },
   "source": [
    "### Load the label files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4fTN5NwQVpWP"
   },
   "outputs": [],
   "source": [
    "simple_model_subset = pd.read_csv(simple_model_subset_path, index_col=0)\n",
    "\n",
    "cnn_subset = pd.read_csv(cnn_subset_path, index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uoaOwfiuVpWS",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(simple_model_subset)\n",
    "print(cnn_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZB0d8FtVpWU"
   },
   "source": [
    "### Define a function for loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nzaywC90VpWZ"
   },
   "outputs": [],
   "source": [
    "# Loading a single image at a time, resizing it to a constant size in order to avoid discrepancies while plotting images or building models\n",
    "def image_loader(image_path):\n",
    "  image=cv2.imread(image_path)\n",
    "  resized_image=cv2.resize(image, (768,768))\n",
    "  return resized_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CST67BPfVpWa"
   },
   "source": [
    "### Define a function for plotting sample images with their labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FB1RxhTAVpWb"
   },
   "outputs": [],
   "source": [
    "def plot_image(image_path, label=-1, plt_axes=121):\n",
    "  fig, ax = plt.subplots(nrows=1,ncols=1,figsize=(10,10))                       # Using matplotlib for plotting images\n",
    "  plt.subplot(plt_axes)\n",
    "\n",
    "  image=image_loader(image_path)                                                # Calling image loader function to load images\n",
    "  plt.imshow(cv2.cvtColor(image,cv2.COLOR_BGR2RGB))\n",
    "\n",
    "  if label==-1:                                                                 # If the label does not exist, here the example images, we speciy that it is not given\n",
    "    plt.title(image_path.split('/')[-1]+\"  :  \"+ \"Self-explanatory Image Name\")\n",
    "  elif label==0:\n",
    "    plt.title(image_path.split('/')[-1]+\"  :  \"+ \"Good Quality Image\")\n",
    "  else:\n",
    "    plt.title(image_path.split('/')[-1]+\"  :  \"+ \"Bad Quality Image\")\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CQob6pC7e5tA"
   },
   "outputs": [],
   "source": [
    "# Plot example images and see if the above functions work\n",
    "example_images=\"/content/gdrive/My Drive/Colab Data/Data/examples/\"\n",
    "sample_images=glob.glob(example_images+'*')\n",
    "\n",
    "for image in sample_images:\n",
    "  plot_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpMZrY_hVpWc"
   },
   "source": [
    "### Plot and observe the differences between the bad and good images on a data subset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5jvrFFt3VpWd"
   },
   "outputs": [],
   "source": [
    "#Plot some good quality images randomly\n",
    "\n",
    "good_quality_images=simple_model_subset.loc[simple_model_subset['quality']==0]\n",
    "\n",
    "for idx, row in good_quality_images.sample(25).iterrows():\n",
    "  plot_image(str(image_path)+'/'+row['image'], label=row['quality'], plt_axes=121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VMoetXO_jXNG"
   },
   "outputs": [],
   "source": [
    "# Plot some bad quality images randomly\n",
    "\n",
    "bad_quality_images=simple_model_subset.loc[simple_model_subset['quality']==1]\n",
    "\n",
    "for idx, row in bad_quality_images.sample(25).iterrows():\n",
    "  plot_image(str(image_path)+'/'+row['image'], label=row['quality'], plt_axes=121)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xArZ4mNZVpWe"
   },
   "source": [
    "### Explore the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R1KGmsSCVpWf",
    "outputId": "a7d216f8-5165-40c7-b03f-92ff049f98c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prevalence of Bad quality Images: 50.0\n",
      "Prevalence of Bad quality Images: 50.0\n"
     ]
    }
   ],
   "source": [
    "# Check the prevalence of  bad quality images in both the sets\n",
    "\n",
    "percentage_of_bad_quality_images=(sum(simple_model_subset['quality'])*100/len(simple_model_subset))\n",
    "print (\"Prevalence of Bad quality Images: \"+ str(percentage_of_bad_quality_images ))\n",
    "\n",
    "percentage_of_bad_quality_images=(sum(cnn_subset['quality'])*100/len(cnn_subset))\n",
    "print (\"Prevalence of Bad quality Images: \"+ str(percentage_of_bad_quality_images ))\n",
    "\n",
    "# Now that we know that the classes are balanced, we will use the default loss functions and not penalize one above the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OfSw_ldqk_rF"
   },
   "outputs": [],
   "source": [
    "# Now let's check the pixel values in the images\n",
    "\n",
    "images=np.zeros((len(simple_model_subset),768,768,3))\n",
    "\n",
    "for idx, row in simple_model_subset.iterrows():\n",
    "  image=image_loader(str(image_path)+'/'+row['image'])\n",
    "  images[idx]=image\n",
    "  print (\"Processing: \"+ str(idx)+ \"th image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ph2FKbt1mQ5M",
    "outputId": "0ef6f3d9-a39b-4bd6-b1e6-54eadde07e44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 255.0\n"
     ]
    }
   ],
   "source": [
    "print (np.min(images), np.max(images))\n",
    "\n",
    "# The images look normalized in a particular range, so we won't probably have to work on fixing the ranges by the looks of it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N03CywODVpWf"
   },
   "source": [
    "# Step 1: Simple Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OnNnNaHvVpWg"
   },
   "source": [
    "Now that we gained insights about the dataset, we can start building models for predicting image quality. In this section, build a model for classifying the images into good and bad classes only using the small data subset. This subset has 300 images from good (label 0) and bad (label 1) classes. Given the size of the dataset, we do not expect you to train a neural network in this section. Feel free to use any other model you like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B52A9QnuVpWh"
   },
   "outputs": [],
   "source": [
    "# Preparing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "2PJVJfJ4qIbL"
   },
   "outputs": [],
   "source": [
    "# Split the data keeping in mind the prevalence(Stratifed split)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(list(simple_model_subset['image']),list(simple_model_subset['quality']),test_size=0.20,random_state=42,stratify=list(simple_model_subset['quality']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E_8LcfKG0cn5"
   },
   "outputs": [],
   "source": [
    "images=np.zeros((len(X_train),64*64*3))\n",
    "labels=[0]*len(X_train)\n",
    "\n",
    "for idx, row in enumerate(X_train):\n",
    "  image=image_loader(str(image_path)+'/'+row)\n",
    "  image=cv2.resize(image, (64, 64))\n",
    "  images[idx]=image.flatten()\n",
    "  labels[idx]=Y_train[idx]\n",
    "  print (\"Processing: \"+ str(idx)+ \"th image\")\n",
    "\n",
    "labels=np.array(labels)\n",
    "\n",
    "x_train /= 255.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "utN2aKVC0uId"
   },
   "outputs": [],
   "source": [
    "images=np.zeros((len(X_test),64*64*3))\n",
    "labels=[0]*len(X_test)\n",
    "\n",
    "for idx, row in enumerate(X_test):\n",
    "  image=image_loader(str(image_path)+'/'+row)\n",
    "  image=cv2.resize(image, (64, 64))\n",
    "  images[idx]=image.flatten()\n",
    "  labels[idx]=Y_test[idx]\n",
    "  print (\"Processing: \"+ str(idx)+ \"th image\")\n",
    "\n",
    "labels=np.array(labels)\n",
    "\n",
    "x_test /= 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AHgIIlswVpWh"
   },
   "source": [
    "### Q: Define a model for training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6STrGYyOVpWi"
   },
   "source": [
    "Tell us why you picked this model. What are the advantages/disadvantages?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UA45vsTqVpWj"
   },
   "source": [
    "### Your Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-UKLAXbsDRi"
   },
   "outputs": [],
   "source": [
    "# XGboost is a ensemble-tree based classifier. The boosting algorithms work on iterative classification minimizing error in subsequent trees. The final ensemble usually helps build the best one. \n",
    "# Since images have a ton of features, I think other algorithms are too like KNN are too simple and might underfit when trained on more amoount of data.\n",
    "# Decision trees on the other hand are prone to overfitting and might not generalize well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "A80XoBeiVpWj"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sklearn.metrics as metrics \n",
    "\n",
    "model = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMj-a9m9VpWk"
   },
   "source": [
    "### Q: Metrics\n",
    "\n",
    "- Explain what metrics you will use for evaluating model performance. \n",
    "- If the task was multi level classification (good, accept, bad), what metrics would you be looking at?\n",
    "- In the case where data is not evenly distributed accross classes, how would you modify the mentioned metrics or add other metrics to best present your model performance?\n",
    "\n",
    "### Your Answer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "brEJ5LSSVpWk"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "1. Generally, I would prefer looking at the classification report and the confusion matrix altogether to get a better hang of the model performance. But here I think, since the classes are balanced\n",
    "  we can look at the F1-score to understand how each of the classes perform. \n",
    "  From a overall product point of view, I think this model can be seen as a screening tool, so picking out bad quality images and removing them is more important because they would otherwise hamper the performance of \n",
    "  other models in the pipeline. So, specifically precision of good quality images is really important from that standpoint \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5lRUmXukVpWl"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "2. If this model was a multi-class/multi-level classification model and the classes are imbalanced, I would still look at the F1-score of each of the classes and accordingly penalize the losses in experiments if required.\n",
    " Since, again F1-score is the harmonic mean of precision and recall, I think we get the best of both worlds\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lCVvmPUQVpWo"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "3. If the data is not evenly distributed, we can use Sensitivity/Recall and Specificity for the model to understand the model performance better. For example, lets say the prevalence of bad quality images is 10%.\n",
    "So I can cap the sensitivity at 90% and and try and the get the best specificity for the model. To determine the best sensitivity-specificity combination that aligns with the business metrics, \n",
    "we can use the ROC curve to determine the threshold for the model. I think for binary/multiclass classification its tough to just rely on a single metric, otherwise AUC score would have been a good metric to justify the overall model\n",
    "performance.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21lFNI7gVpWp"
   },
   "source": [
    "### Q: Train & Test\n",
    "\n",
    "Train/test the model of your choice and present the results. \n",
    "\n",
    "### Your Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aH4Jbv3vVpWp",
    "outputId": "fc6d4402-5c78-4625-a6f5-be71783e861b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:   12.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:   12.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0.91666667 0.86666667]\n",
      "\n",
      "XGBClassifier()\n"
     ]
    }
   ],
   "source": [
    "cv_results = cross_val_score(model, x_train, y_train, \n",
    "                cv = 2, scoring='accuracy', n_jobs = -1, verbose = 1)    \n",
    "\n",
    "model.fit(x_train, y_train, verbose=True)\n",
    "\n",
    "print(); print(cv_results)    \n",
    "print(); print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S-fNJ6mJVpWq",
    "outputId": "61c3f8ca-10e7-4a00-b7e5-a8ab2643af97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.80      0.84        30\n",
      "           1       0.82      0.90      0.86        30\n",
      "\n",
      "    accuracy                           0.85        60\n",
      "   macro avg       0.85      0.85      0.85        60\n",
      "weighted avg       0.85      0.85      0.85        60\n",
      "\n",
      "\n",
      "[[24  6]\n",
      " [ 3 27]]\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "expected_y  = y_test\n",
    "predicted_y = model.predict(x_test)\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(); print(metrics.classification_report(expected_y, predicted_y))\n",
    "print(); print(metrics.confusion_matrix(expected_y, predicted_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3cHCaGjVpWq"
   },
   "source": [
    "### Q: Plotting Predictions\n",
    "\n",
    "Part of making a good model is visualizing the results. Update the image plotting function to inspect where the model is working and where it is not. \n",
    "\n",
    "### Your Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "52ELW6jPVpWr"
   },
   "outputs": [],
   "source": [
    "# Plot images where the model is working\n",
    "for idx, row in enumerate(expected_y):\n",
    "  if row==predicted_y[idx]:\n",
    "    plot_image(str(image_path)+'/'+X_test[idx], label=row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cCIMcsrtVpWr"
   },
   "outputs": [],
   "source": [
    "# Plot images where the model is not working\n",
    "\n",
    "for idx, row in enumerate(expected_y):\n",
    "  if row!=predicted_y[idx]:\n",
    "    plot_image(str(image_path)+'/'+X_test[idx], label=row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMixFeEoVpWs"
   },
   "source": [
    "### Q: Improvements \n",
    "\n",
    "Describe what steps, if any, should be taken to make the model perform better.\n",
    "\n",
    "### Your Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "kYiUe0a3VpWs",
    "outputId": "5f95c98e-8388-4d67-8b61-2edcdaae268d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n1. I think the current model performance is decent with the number of the images it has been trained on. But in order to further improve, we can use Grid Search CV to figure out optimal hyperparameters.\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1. I think the current model performance is decent with the number of the images it has been trained on. But in order to further improve, we can use Grid Search CV to figure out optimal hyperparameters.\n",
    "2. Trying out other models like Random Forest and maybe some other traditional ML algorithms would help\n",
    "3. On looking at the above images, it feels the model is misclassifying on images where the brightness and contrast lies in a confusing range. One way to fix this would be using photometric augmentations to perform better.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TrxaeOIRVpWt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MkDilTpvVpWu"
   },
   "source": [
    "# Step 2: CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pAz2WqMpVpWv"
   },
   "source": [
    "In this section, we will train a CNN model to classify the images into good and bad classes using the larger data subset. This dataset has 1000 images good (label 0) and bad (label 1) classes. Feel free to use any model including \n",
    "pre-trained models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "gAc9D579VpWv"
   },
   "outputs": [],
   "source": [
    "imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
    "imagenet_std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "def img_standardization(x):\n",
    "    \n",
    "    x=x.astype('float16')/255.\n",
    "    return ((x-imagenet_mean)/imagenet_std)\n",
    "\n",
    "# Training batch generator\n",
    "def batch_generator(X, Y, batch_size = 32):\n",
    "    indices = np.arange(len(X))\n",
    "    batch=[]\n",
    "    while True:\n",
    "            # it might be a good idea to shuffle your data before each epoch\n",
    "            np.random.shuffle(indices)\n",
    "            for i in indices:\n",
    "                batch.append(i)\n",
    "                if len(batch)==batch_size:\n",
    "                    x=img_standardization(x)\n",
    "                    yield x, Y[batch]\n",
    "                    batch=[]\n",
    "\n",
    "\n",
    "# Validation Batch Generator\n",
    "def batch_generator_val(X, Y, batch_size = 32):\n",
    "    indices = np.arange(len(X))\n",
    "    batch=[]\n",
    "    while True:\n",
    "            for i in indices:\n",
    "                batch.append(i)\n",
    "                if len(batch)==batch_size:\n",
    "                    x=img_standardization(x)\n",
    "                    yield x, Y[batch]\n",
    "                    batch=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "N4ejbcDCVpWw"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_val,Y_train,Y_val=train_test_split(list(cnn_subset['image']),list(cnn_subset['quality']),test_size=0.20,random_state=42,stratify=list(cnn_subset['quality']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "6hBKNGXpzyIM"
   },
   "outputs": [],
   "source": [
    "def dataloader(files, labels, batchsize):\n",
    "  inputs = []\n",
    "  targets = []\n",
    "  batchcount = 0\n",
    "  while True:\n",
    "    for idx, image in enumerate(files):\n",
    "        inputs.append(cv2.resize(cv2.imread(str(image_path)+'/'+image), (224,224)))\n",
    "        targets.append(labels[idx])\n",
    "        batchcount += 1\n",
    "        if batchcount > batchsize:\n",
    "          X = np.array(inputs, dtype='float32')\n",
    "          X=img_standardization(X)\n",
    "\n",
    "          y = np.array(targets, dtype='float32')\n",
    "          y=to_categorical(y,num_classes=2)\n",
    "\n",
    "          yield (X, y)\n",
    "          inputs = []\n",
    "          targets = []\n",
    "          batchcount = 0\n",
    "\n",
    "\n",
    "def predict_dataloader(files, batchsize):\n",
    "  inputs = []\n",
    "  targets = []\n",
    "  batchcount = 0\n",
    "  while True:\n",
    "    for idx, image in enumerate(files):\n",
    "        inputs.append(cv2.resize(cv2.imread(str(image_path)+'/'+image), (224,224)))\n",
    "        batchcount += 1\n",
    "        if batchcount > batchsize:\n",
    "          X = np.array(inputs, dtype='float32')\n",
    "          X=img_standardization(X)\n",
    "\n",
    "          yield (X)\n",
    "          inputs = []\n",
    "          targets = []\n",
    "          batchcount = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CyvPzT3gVpWw"
   },
   "source": [
    "## Q: Loss function\n",
    "\n",
    "Your model predicts the quality of an image. At this step we have two classes: good and bad. Tell us which loss function you will be using & why?\n",
    "\n",
    "### Your Answer:\n",
    "Intuitively, since it's a classification problem I'll start with binary crossentropy which is a log loss, since it penalizes the more on classes predicted incorrectly with high confidence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "r-AjbHht68ox"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-RcKQEmeVpW0",
    "outputId": "021932dd-e76a-479e-b132-f9012a5a21b7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "29089792/29084464 [==============================] - 1s 0us/step\n",
      "29097984/29084464 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "adam=Adam(lr=1e-3)\n",
    "\n",
    "#Model declaration:VGG \n",
    "# dense_model = VGG16(weights='imagenet', include_top=False,input_shape=(224,224,3),pooling='avg')     #Did not work out well\n",
    "\n",
    "dense_model = DenseNet121(weights='imagenet', include_top=False,input_shape=(224,224,3),pooling='avg')\n",
    "preds = Dense(2,activation='softmax')(dense_model.output)\n",
    "model = Model(dense_model.input,preds)\n",
    "\n",
    "#Model parameters for compiling\n",
    "\n",
    "model.compile(optimizer=adam,loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "8BUmCLTTVpW0"
   },
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint(\n",
    "        os.path.join(str(data_path), 'Best_Good_Bad_Quality_Image_Weights.hdf5'),\n",
    "        monitor='val_loss', mode='min',save_best_only=True, verbose=1, save_weights_only=True)\n",
    "\n",
    "#Callback for reducing learning rate based on validation loss\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,patience=3, min_delta=0.0001, verbose=1, min_lr=0.000001)\n",
    "\n",
    "#Callback for storing logs of learning rate, loss and accuracy\n",
    "csvlogger=CSVLogger('model_metrics_tracker.csv')\n",
    "\n",
    "callbacks = [model_checkpoint,reduce_lr,csvlogger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jR61ZBV1VpW1"
   },
   "outputs": [],
   "source": [
    "# Required in case of class imbalance\n",
    "'''\n",
    "from sklearn.utils import class_weight\n",
    "y_true=np.argmax(Y_train,axis=-1)\n",
    "weights = class_weight.compute_class_weight('balanced',np.unique(y_true),y_true)\n",
    "print(weights)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okHrA_xbVpW5"
   },
   "source": [
    "## Q: Train the model\n",
    "\n",
    "### Your Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7-iz6PdqVpW6"
   },
   "outputs": [],
   "source": [
    "history=model.fit_generator(dataloader(X_train, Y_train, batchsize=32),validation_data=dataloader(X_val, Y_val, batchsize=32),steps_per_epoch=len(X_train) / 32, epochs=100,callbacks=callbacks,verbose=1, shuffle=True, validation_steps=len(X_val)/32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEtxtweRVpW7"
   },
   "source": [
    "## Q: Training Metrics\n",
    "\n",
    "Plot the loss and any other metric of interest on the training and validation data. What observations or comments can you making regarding the training job?\n",
    "\n",
    "### Your Answer:\n",
    "I think the model has trained well. Since the images are less, we can started with a lower learning rate and a simpler model. Certain model improvement techniques can further improve the performance I feel. Something like cyclic learning rates helps model jump out of local minima or maybe augmentations can further help. Experimentation with other other model architectures can help as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "cVFYHb_F_iQl"
   },
   "outputs": [],
   "source": [
    "csv=pd.read_csv('model_metrics_tracker.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "FjjS0gveFSb6",
    "outputId": "2d9f83f7-4559-4875-d81a-a40bc3100f51"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-802aa000-0df5-435b-8e2b-2be20ab0648a\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>lr</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.736970</td>\n",
       "      <td>0.587455</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.493506</td>\n",
       "      <td>1.671517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.513272</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.623377</td>\n",
       "      <td>0.931494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.802424</td>\n",
       "      <td>0.429920</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.519481</td>\n",
       "      <td>2.674115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.830303</td>\n",
       "      <td>0.375885</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>1.795951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.846061</td>\n",
       "      <td>0.354695</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>4.243829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.892121</td>\n",
       "      <td>0.255251</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.627706</td>\n",
       "      <td>1.982323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.170945</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.709957</td>\n",
       "      <td>1.224142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.963636</td>\n",
       "      <td>0.125631</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.774892</td>\n",
       "      <td>0.826081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.976970</td>\n",
       "      <td>0.095413</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.783550</td>\n",
       "      <td>0.674267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.985455</td>\n",
       "      <td>0.061960</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.547842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.992727</td>\n",
       "      <td>0.038344</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.813853</td>\n",
       "      <td>0.533225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.997576</td>\n",
       "      <td>0.027806</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.619220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.998788</td>\n",
       "      <td>0.020246</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.566542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.997576</td>\n",
       "      <td>0.014684</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.553211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.998788</td>\n",
       "      <td>0.008742</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.600637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-802aa000-0df5-435b-8e2b-2be20ab0648a')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-802aa000-0df5-435b-8e2b-2be20ab0648a button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-802aa000-0df5-435b-8e2b-2be20ab0648a');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "    epoch  accuracy      loss       lr  val_accuracy  val_loss\n",
       "0       0  0.736970  0.587455  0.00100      0.493506  1.671517\n",
       "1       1  0.746667  0.513272  0.00100      0.623377  0.931494\n",
       "2       2  0.802424  0.429920  0.00100      0.519481  2.674115\n",
       "3       3  0.830303  0.375885  0.00100      0.606061  1.795951\n",
       "4       4  0.846061  0.354695  0.00100      0.523810  4.243829\n",
       "5       5  0.892121  0.255251  0.00010      0.627706  1.982323\n",
       "6       6  0.939394  0.170945  0.00010      0.709957  1.224142\n",
       "7       7  0.963636  0.125631  0.00010      0.774892  0.826081\n",
       "8       8  0.976970  0.095413  0.00010      0.783550  0.674267\n",
       "9       9  0.985455  0.061960  0.00010      0.805195  0.547842\n",
       "10     10  0.992727  0.038344  0.00010      0.813853  0.533225\n",
       "11     11  0.997576  0.027806  0.00010      0.792208  0.619220\n",
       "12     12  0.998788  0.020246  0.00010      0.792208  0.566542\n",
       "13     13  0.997576  0.014684  0.00010      0.809524  0.553211\n",
       "14     14  0.998788  0.008742  0.00001      0.787879  0.600637"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "RUnloQc4VpW7",
    "outputId": "df2d65ae-1343-4d01-c57f-d8841ec0539c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xV9f3H8dcnm5AAgbBkJSBDQFkBHKio1CIOHHWLtVpxr9ZWu9RaW+2vw1Zr66qrIg5caHGBgFoRCAiy90iAQCAEwsj+/P74nsAFknAJuTm5936ej0ce3nvPuee+byTnc77f8z3fI6qKMcaY6BXjdwBjjDH+skJgjDFRzgqBMcZEOSsExhgT5awQGGNMlLNCYIwxUc4KgYkqIvKSiDwS5LprRWREqDMZ4zcrBMYYE+WsEBgThkQkzu8MJnJYITCNjtcl8zMR+U5EdovIv0WkrYh8JCJFIjJZRNIC1r9ARBaJSKGITBOR4wKWDRCRud773gCSDvqs80Rknvfer0XkhCAznisi34rIThHJEZGHDlo+zNteobf8Ou/1JiLyFxFZJyI7ROQr77XhIpJbze9hhPf4IRGZICKvishO4DoRGSIiM7zP2CQi/xCRhID39xGRz0SkQEQ2i8gvRaSdiOwRkVYB6w0UkXwRiQ/mu5vIY4XANFaXAN8DegDnAx8BvwRa4/7d3gkgIj2A8cDd3rJJwAcikuDtFN8D/gO0BN7ytov33gHAC8BNQCvgGWCiiCQGkW83cC3QAjgXuEVELvS228XL+6SXqT8wz3vfn4FBwMlepp8DlUH+TkYDE7zPHAdUAPcA6cBJwFnArV6GVGAy8DFwDHAsMEVV84BpwGUB2x0DvK6qZUHmMBHGCoFprJ5U1c2qugH4Epipqt+qajHwLjDAW+9y4L+q+pm3I/sz0AS3oz0RiAf+pqplqjoBmB3wGWOBZ1R1pqpWqOrLQIn3vlqp6jRVXaCqlar6Ha4Yne4tvgqYrKrjvc/dpqrzRCQGuB64S1U3eJ/5taqWBPk7maGq73mfuVdV56jqN6parqprcYWsKsN5QJ6q/kVVi1W1SFVnesteBq4BEJFY4EpcsTRRygqBaaw2BzzeW83zFO/xMcC6qgWqWgnkAB28ZRv0wJkV1wU87gL81OtaKRSRQqCT975aichQEZnqdansAG7GHZnjbWNVNW9Lx3VNVbcsGDkHZeghIh+KSJ7XXfSHIDIAvA/0FpFMXKtrh6rOqmMmEwGsEJhwtxG3QwdARAS3E9wAbAI6eK9V6RzwOAf4vaq2CPhJVtXxQXzua8BEoJOqNgeeBqo+JwfoVs17tgLFNSzbDSQHfI9YXLdSoIOnCv4XsBTorqrNcF1ngRm6Vhfca1W9iWsVjMFaA1HPCoEJd28C54rIWd7Jzp/iune+BmYA5cCdIhIvIhcDQwLe+xxws3d0LyLS1DsJnBrE56YCBapaLCJDcN1BVcYBI0TkMhGJE5FWItLfa628APxVRI4RkVgROck7J7EcSPI+Px74NXC4cxWpwE5gl4j0Am4JWPYh0F5E7haRRBFJFZGhActfAa4DLsAKQdSzQmDCmqouwx3ZPok74j4fOF9VS1W1FLgYt8MrwJ1PeCfgvdnAjcA/gO3ASm/dYNwKPCwiRcADuIJUtd31wChcUSrAnSju5y2+F1iAO1dRAPwRiFHVHd42n8e1ZnYDB4wiqsa9uAJUhCtqbwRkKMJ1+5wP5AErgDMClv8Pd5J6rqoGdpeZKCR2YxpjopOIfA68pqrP+53F+MsKgTFRSEQGA5/hznEU+Z3H+Mu6hoyJMiLyMu4ag7utCBiwFoExxkQ9axEYY0yUC7uJq9LT0zUjI8PvGMYYE1bmzJmzVVUPvjYFCMNCkJGRQXZ2tt8xjDEmrIhIjcOErWvIGGOinBUCY4yJclYIjDEmyoXdOYLqlJWVkZubS3Fxsd9RQiopKYmOHTsSH2/3DzHG1J+IKAS5ubmkpqaSkZHBgRNNRg5VZdu2beTm5pKZmel3HGNMBAlZ15CIvCAiW0RkYQ3LRUSeEJGV4m5JOLCun1VcXEyrVq0itggAiAitWrWK+FaPMabhhfIcwUvAyFqWnwN0937G4uZWr7NILgJVouE7GmMaXsi6hlT1CxHJqGWV0cAr3t2jvhGRFiLSXlU3hSqTMSY8FZdVUFpRSXmFUlZRSWl5JeWV7rH7OehxeSXllZWUVijl3uuBj6vWr1RIiBXiYmOIj4054HF8rHj/jSEuVkiIjSEuRoiPi3GPveWBj+NjYoiPE1Q54HPKK5RS77OrHpdXk7u80n23wMflle77lFVUctZxbenXqUW9/379PEfQgQNvvZfrvXZIIRCRsbhWA507dz54se8KCwt57bXXuPXWW4/ofaNGjeK1116jRYv6/x9rTGNWUals31PKtl2lbNtVQv6uEvd4t/vv1l0lbPWeby0qZW9Zhd+RG4W2zZMirhAETVWfBZ4FyMrKanSz5BUWFvLPf/7zkEJQXl5OXFzNv+JJkyaFOpoxDaaiUsnbWUx+UQlbi0rcTtzbqW8L2Klv211Cwe5SKqv5S46NEVo2TSA9JZH0lAQyWiWTnpJIWtMEEuP2H50fciQecPRe3eM473FCwOP4mBhECGhZ7D8633/U7rVAAh5X2wLxjvBLvccxAnExMcTHxRAf4+UJeFzVwoiP81oZNWSP875nfKwQGyMh6x72sxBswN1btkpH77Wwc//997Nq1Sr69+9PfHw8SUlJpKWlsXTpUpYvX86FF15ITk4OxcXF3HXXXYwdOxbYP13Grl27OOeccxg2bBhff/01HTp04P3336dJkyY+fzNj9lNVCveUkbN9D+sL9pBTsJf1BXvI9Z5v2L6X8mr27imJcbRKSaBV0wS6tEpmYJc00lPczt69nrjvefMm8cTENOy5sKqdbzTzsxBMBG4XkdeBocCO+jg/8NsPFrF4486jDheo9zHNePD8PjUuf+yxx1i4cCHz5s1j2rRpnHvuuSxcuHDfMM8XXniBli1bsnfvXgYPHswll1xCq1atDtjGihUrGD9+PM899xyXXXYZb7/9Ntdcc029fg9jDqe4rILc7XvJ2b6HnAL3s75gD+sL9pJbsIeikvID1m/ZNIFOaU04vkNzRh3fnk5pybRtlrhvJ5+ekkhSfKxP38YEK2SFQETGA8OBdBHJBR4E4gFU9WlgEu6+riuBPcCPQpWloQ0ZMuSAsf5PPPEE7777LgA5OTmsWLHikEKQmZlJ//79ARg0aBBr165tsLwmuhTsLmV1/i7Wbas6st+z7yh/886SA9ZNjIuhU8tkOrdMZkhGGp1aJu973qllMimJYdG7bA4jlKOGrjzMcgVuq+/Pre3IvaE0bdp03+Np06YxefJkZsyYQXJyMsOHD6/2WoDExMR9j2NjY9m7d2+DZDWRqaS8gvXb9rAqfzert+5idf5uVufvYvXW3RTuKdu3ngi0b5ZEp5bJnNq9tbeDb+L+m5ZM69REG7YcBayc14PU1FSKiqq/49+OHTtIS0sjOTmZpUuX8s033zRwOhOpVJX8XSXeTn43q/J37dvZ5xTsOeBkbJvURLq2bsqo49vTNb0p3Vqn0KVVMh3SmpAYZ1030c4KQT1o1aoVp5xyCn379qVJkya0bdt237KRI0fy9NNPc9xxx9GzZ09OPPFEH5OacFRcVsGarbsPOKpfne+O8gP77BPjYshMb0rfY5ozut8xdG2dQtfWTclMb0pqks1PZWoWdvcszsrK0oNvTLNkyRKOO+44nxI1rGj6rtEqb0cxs9YWMHtNAbPWFLB8SxGBf6bHNE/at5Pvmt503+Njmjdp8BE3JnyIyBxVzapumbUIjPGRqrJ22x5mrylg5poCZq8tYH3BHgCaJsQysEsaI/u249g2+4/ukxPsz9bUL/sXZUwDqqhUluUVMWvNNmav3c6stQXkF7mROi2bJjA4I41rT+rC0MxWHNc+lbgoH99uGoYVAmNCqLS8kgUbCpm1Zjuz17oj/qJi169/TPMkTunWisGZLRma2ZJurVNshI7xhRUCY+rRntJy5q4rZNbaAmat2ca8nEKKyyoB6Na6Keed0J4hmS0ZnNGSjmnJPqc1xrFCYMxR2ltawbvfbuDN7BwWbNhBRaUSI+6K9CuHdGZoZkuyMlqSnpJ4+I0Z4wMrBMbU0aYde3llxjrGz1pP4Z4yjmvfjJtO68qQzJYM6pJmQzZN2LBC4IOUlBR27drldwxTR3PXb+eFr9bw0cI8VJWze7fj+mGZDM5Isz5+E5asEBgThLKKSiYt2MSL/1vLvJxCUpPiuP6UDK49KYNOLa2v34Q3KwT14P7776dTp07cdpubOumhhx4iLi6OqVOnsn37dsrKynjkkUcYPXq0z0nNkdq+u5TXZq3nPzPWkbezmMz0pjw8ug+XDOxIU5twzUSIyPuX/NH9kLegfrfZ7ng457EaF19++eXcfffd+wrBm2++ySeffMKdd95Js2bN2Lp1KyeeeCIXXHCBdR2EieWbi3jxf2t4Z+4GSsorObV7On+4uC/De7Sxq3dNxIm8QuCDAQMGsGXLFjZu3Eh+fj5paWm0a9eOe+65hy+++IKYmBg2bNjA5s2badeund9xTQ0qK5Vpy7fwwldr+WrlVhLjYrh4YAeuOzmTnu1S/Y5nTMhEXiGo5cg9lC699FImTJhAXl4el19+OePGjSM/P585c+YQHx9PRkZGtdNPG//tLilnwpxcXvp6LWu27qZts0R+9v2eXDmkMy2bJvgdz5iQi7xC4JPLL7+cG2+8ka1btzJ9+nTefPNN2rRpQ3x8PFOnTmXdunV+RzQHySnYwysz1vL67ByKisvp36kFT1w5gHP6tov6Wxea6GKFoJ706dOHoqIiOnToQPv27bn66qs5//zzOf7448nKyqJXr15+RzSeOeu289wXq/l0cR4iwqjj2/OjUzIY2DnN72jG+MIKQT1asGD/Ser09HRmzJhR7Xp2DYE/VJVnvljNYx8tpUVyPDef3o0xJ3WhffMmfkczxldWCExUKC2v5DfvLeSN7BzOO6E9//eDE2w6Z2M89pdgIt6OPWXc/OocZqzexh1nHss9I3rYEFBjAkRMIVDViB+jH253k2sM1m3bzY9emk1OwR7+cmk/LhnU0e9IxjQ6EVEIkpKS2LZtG61atYrYYqCqbNu2jaSkJL+jhI3ZawsY+0o2Crx6w1CGdm3ldyRjGqWIKAQdO3YkNzeX/Px8v6OEVFJSEh072hFtMN79Npf7JiygY1oTXrhuMBnpTf2OZEyjFRGFID4+nszMTL9jmEZAVXl88gqemLKCk7q24l/XDKRFsl0UZkxtIqIQGANQXFbBzyd8x8T5G7ksqyOPXHg8CXF2YZgxh2OFwESErbtKGPtKNnPXF3LfyF7cfHrXiD1fZEx9s0Jgwt6KzUX86KXZ5BeV8K+rB3LO8e39jmRMWLFCYMLalyvyufXVuSTGx/LGTSfRv1MLvyMZE3asEJiwNW7mOh54fxHd26Tw7+sG06GFTRVhTF1YITBhp6JSeXTSEp7/ag3De7bmySsH2I3ijTkKIR1SISIjRWSZiKwUkfurWd5FRKaIyHciMk1EbJC8qdXuknJu+s8cnv9qDdednMHz12ZZETDmKIWsRSAiscBTwPeAXGC2iExU1cUBq/0ZeEVVXxaRM4FHgTGhymTC26Yde7nhpWyW5u3ktxf04YcnZ/gdyZiIEMquoSHASlVdDSAirwOjgcBC0Bv4ifd4KvBeCPOYMLZwww5ueHk2u4rL+fcPB3NGrzZ+RzImYoSya6gDkBPwPNd7LdB84GLv8UVAqogcMiGMiIwVkWwRyY70aSTMoT5dlMelT88gVoQJt5xsRcCYeub3ZZf3AqeLyLfA6cAGoOLglVT1WVXNUtWs1q1bN3RG4xNV5bkvVnPTq3Po0TaF924/hePaN/M7ljERJ5RdQxuATgHPO3qv7aOqG/FaBCKSAlyiqoUhzGTCRFlFJQ+8v4jxs9Yz6vh2/OXS/jRJiPU7ljERKZSFYDbQXUQycQXgCuCqwBVEJB0oUNVK4BfACyHMY8LE9t2l3DJuDt+sLuDW4d249+yediMZY0IoZIVAVctF5HbgEyAWeEFVF4nIw0C2qk4EhgOPiogCXwC3hSqPCQ/LNxfx45ezydtZzOOX9+OiATai2JhQk3C761VWVpZmZ2f7HcOEwOdLN3Pn+Hkkxcfy7LWDGNg5ze9IxkQMEZmjqlnVLbMri43vVJXnvlzNox8tpXf7Zjx3bRbH2HQRxjQYKwTGVyXlFfzynYW8PTeXUce348+X9iM5wf5ZGtOQ7C/O+GbrrhJu+s8c5qzbzt0junPnmd3tpLAxPrBCYHyxeONObnwlm227S3jqqoGce4LdQ8AYv1ghMA3uk0V53PPGPJolxfPWTSdzfMfmfkcyJqpZITANRlX557RV/OmTZfTr1ILnxgyiTbMkv2MZE/WsEJgGEXhj+Qv7H8Njl5xAUrxdKWxMY2CFwITc5p3FjH0lm/m5O/jZ93ty6/BudmN5YxoRKwQmpL7LLeTGV7IpKi7n2TGDOLtPO78jGWMOYoXAhMwH8zdy71vzSU9JZMLNJ9P7GJs51JjGyAqBqXeVlcrfJi/nic9XktUljafHDCI9JdHvWMaYGlghMPVqT2k5P31zPh8tzOPSQR155KK+JMbZSWFjGjMrBKbebCzcy49fdvcU/vW5x3HDsEw7KWxMGLBCYOrFnHXbuek/cygpq7B7ChsTZqwQmDrbU1rON6u3MW1ZPq/PyqFd8yTG3ziU7m1T/Y5mjDkCVghM0FSVVfm7mLYsn+nL85m5poDS8kqaxMfyvT5teWR0X9KaJvgd0xhzhKwQmFrtKinn65VbmbY8n+nL8tlQuBeAY9ukcO2JXTi9Z2sGZ7S0q4SNCWNWCMwBVJVlm4uYviyfacvyyV5XQFmF0jQhlpOPTefWM7pxeo/WdExL9juqMaaeWCEw7Cwu438rtjJ9uevy2bSjGIBe7VK5flgmp/doTVaXliTExfic1BgTClYIopCqsnjTzn19/XPXbae8UklNjGNY93TuHtGa03u0oV1zmxnUmGhghSCKLN64k5e+XsPUZfnkF5UA0OeYZtx0eldO79GGAZ1bEB9rR/3GRBsrBFFgyaad/H3yCj5elEdKYhzDe7ZmeM82nNYjnTapdtRvTLSzQhDBlua5AvDRwjxSE+O486zu3HBKJs2T4/2OZoxpRKwQRKBleUX8fcpyJi2wAmCMOTwrBBFkWV4RT0xZwX8XbCIlMY47zzyW64dl0iLZLvIyxtTMCkEEWL65iL9PWcGkBZtomhDHHWceyw1WAIwxQbJCEMZWeAXgvws2kRwfy23DXQGwaR6MLyoroGgTpLaHGLvSPJxYIQhDKzYX8cTnK/nwu40kx8dy6/Bu/HhYVysApmGUFMHWFd7Pcu9nBRSsgopSSD0GBlwNA66BtAy/05ogWCEIIyu3FPHElJV84BWAW07vxo2nWgEwIaAKOzfs38nv++8KKNq4fz2JhZaZkN4DepwNzTrCys/gy7/AF3+CrsNhwBjodR7ER8FQ5T0FsHIyJLWAbmdCbHjsYsMjZZRbuWUXT0xZwQffbaRJfCw3ewWgpRUAc7TK9sK2VW5Hv21lwBH+SijbvX+9xOaQ3t3t2NO7ux1/eg93xB930L/DoWNhRy7Mew2+/Q+8fQM0SYMTroCBY6Btnwb8gg1g+1pYOgmW/hfWfw1a6V5PbQ/9vZZRy0xfIx6OqGroNi4yEvg7EAs8r6qPHbS8M/Ay0MJb535VnVTbNrOysjQ7OztEiRuXVfmuAEyc7wrAtSdlMPY0KwDmKFRWwtov4NtxkDMTCtcDVfsAgRad9u/k07tDK2+nn9IG6nK3ucpKWDMd5r4CSz90XUcdBsHAa6HPxZDUrD6/XcNQhbzv3I5/6X9h80L3epve0Otc6HkO7NzovvPKya4wZJ7uvrOPLSMRmaOqWdUuC1UhEJFYYDnwPSAXmA1cqaqLA9Z5FvhWVf8lIr2BSaqaUdt2o6EQlJRX8MB7i3hrTg5JXgG48dRMWtkN4E1d7dwI88bB3P9A4br9XRete+4/wm/ZDRJCOKvsngL47g23g9yyGOKTXTEYeC10GlK3QtNQKspg3dewzDvy35EDCHQ+CXqNgp6joFW3Q98X2DIqXO9+7/2ucN1l7fo26FfwqxCcBDykqt/3nv8CQFUfDVjnGWC1qv7RW/8vqnpybduN9EJQUl7Bra/OZcrSLfx4WCa3DO9mBcDUTUUZLP/EOzL9zDsyPQ0G/tDfPntV2DDH5Vr4NpTucoVo4LWu+yiltT+5DlayC1ZNcd0+yz+G4kKIS4KuZ7gj/x4jg89aXcvomIHuO/e9pEFaRn4Vgh8AI1X1x97zMcBQVb09YJ32wKdAGtAUGKGqc6rZ1lhgLEDnzp0HrVu3LiSZ/VZSXsFt4+YyeckWHrmwL9ec2MXvSCYcbV0J374C88bD7i0BfdVXQ8uufqc7UMkuWPSu20HmzoKYeNe1MvCH0O2Mhh+Guisfln/kjvpXTYWKEncU3/Mct/PvdiYkND26z6hqGc15GfKXBLSMxkCnoSFrGR11IRCRd4B/Ax+pVp0JOex7gikEP/Ey/MVrEfwb6FvbZ0Rqi6C0vJJbx81h8pIt/O7CvoyxImCOROkeWPy+26Gu/9qN5ul5juuCOHZEeIxe2bLUdaHMHw97trkRSAOudkUsLYR/D9tW7e/vz5kJKDTv7Hb8vc513T+h+P3taxm9DAvfCXnLqD4KwQjgR8CJwFvAi6q67DDvCaZraBGuWOR4z1cDJ6rqlpq2G4mFwBWBuUxespnfje7DmJMy/I5kwsXGeW7nv+AtKNnpjvgHXgv9roLUtn6nq5vyEtcXP/c/sOpz91rnk6BJi/r/rILVkL/UPW53vOsy6znKPW7IcxaHtIziXI56bBnVW9eQiDQHrgR+BeQAzwGvqmpZNevG4U4WnwVswJ0svkpVFwWs8xHwhqq+JCLHAVOADlpLqEgrBFYEzBHbux0WTHBHknkLXL917wtdAehycuM+6XqkCte7EU4rPoXKQ3YzRy+5levr7zkqtK2OIxGillG9FAIRaQVcA4wBNgLjgGHA8ao6vIb3jAL+hhsa+oKq/l5EHgayVXWiN1LoOSAFN4bt56r6aW05IqkQlJZXcttrc/ls8WYeHt2Ha60ImJqowtqv3BHjkolQXgzt+3knG38QmqNl46/qWkaj/gRDbqzT5uqja+hdoCfwH+AlVd0UsCy7po2HQqQUgtLySm5/bS6fWhEwNamaymH1VPj2VdeNkdgcTrjMnVhs38/vhKahVLWM+lwEbXrVaRO1FYJgz4A8oapTq1vQkEUgUpRVVHLHeFcEfnuBFYGodshUDgHTOQRO5dBlGJx+P/S+AOKb+JfX+KNFZzjjFyHbfLCFoLeIfKuqhQAikoa7OOyfIUsWocoqXEvgk0Wbeej83vzw5Ay/I5mGUFbsJmU7YO6e6qZyaOZGjnQdDunHusftTmg8/dcmIgVbCG5U1aeqnqjqdhG5EbBCcATKKiq547Vv+WTRZh48vzfXndK45x8xR0gVdm89cEbOqsc1TeXQ+eQD5+6p61QOxhyFYAtBrIhI1Wgeb/oIm/DmCJRVVHLn+G/5eFEeD5zXmx9ZEYgsa7+CCdfDrs37X4tr4o7qO2ZB/6sabioHY45QsIXgY+ANb0oIgJu810wQyioquev1b/loYR6/Oa831w+zIhBR8pfD61dB0zYw7Cf7d/jNOkBMjN/pjDmsYAvBfbid/y3e88+A50OSKMJUFYFJC1wRuMGKQGTZvRVeuxRiE+Cat60v34SloAqBN+XDv7wfE6Syikrufn0ekxbk8etzj7MiEGnKil1LoCgPrvuvFQETtoIqBCLSHXgU6A3sm7JQVRvZDFaNR7lXBP67YBO/Pvc4fnyq/aoiiiq8f5ubm+bSl915AGPCVLAdmC/iWgPlwBnAK8CroQoV7sorKrnrDVcEfjXKikBEmvoHWDgBznoQ+lzodxpjjkqwhaCJqk7BXYm8TlUfAs4NXazwVV5Ryd1vzOO/323il6N6ceNpVgQizrzx8MX/uZk9h93jdxpjjlqwJ4tLRCQGWCEit+MmkUsJXazwVF5RyT1vzufD7zbxi3N6Mfa0au5YZMLb2q9g4h3uBi/nPW5j/k1ECLZFcBeQDNwJDMJNPvfDUIUKR+UVlfzkzfl8MH8j95/Ti5tOtyIQcbauhNevdjciv+wViI33O5Ex9eKwLQLv4rHLVfVeYBfuvgQmQHlFJT99az4T52/kvpG9uNmKQOTZvc0NE42Jg6vehCZpficypt4cthCoaoWIDGuIMOGoqgi8P88VgVuGWxGIOOUl8MbVsGMDXPehaxEYE0GCPUfwrYhMxN2dbN8MWar6TkhSNVKqSn5RCcs2F7Esr4ileUV8l1vI8s27+PnInlYEIlHVMNH1M+AHL0KnIX4nMqbeBVsIkoBtwJkBrykQsYWgqLiM5Zt3sSyviGV5O/ft/Lfv2X+XpPSURHq1S+VHp2Ry5ZDOPqY1ITPtMXcbyDN/A30v9juNMSER7JXFEXteoLS8klX5u1i+2R3hL/N+NhTu3bdO04RYerRL5ft92tGzXar7aZtKq5REH5ObkJv/Bkx/zN0i8NSf+p3GmJAJ9sriF9k/h+4+qnp9vScKkcpKJXf7Xu/IfidL84pYvrmI1fm7Ka90Xy0uRujWOoWBXdK4amhnerZ1O/0OLZoQE2PDBKPKuq9h4u2QcSqc9zcbJmoiWrBdQx8GPE4CLsLdtzhsPPn5Sh6fvHzf845pTejZNpURx7Xdd5TfNT2FhDibLTLqbVvl5hBq0QUu/w/E2YzrJrIF2zX0duBzERkPfBWSRCFy1nFtaNMskR5tU+nRNoXUJBsDbqqxpwDGXQoSA1fbMFETHYJtERysO9CmPoOEWt8OzenbobnfMUxjVl4Cb1wDO3Lghx9AS5sexESHYM8RFHHgOYI83D0KjIkMqjDxTlj3P7jk39D5RL8TGdNggu0aSg11EGN89cWf4LvX4YxfwfE/8DuNMS/XkrEAABdWSURBVA0qqDOjInKRiDQPeN5CRGzuXRMZvnsLpv4e+l0Jp/3M7zTGNLhgh8g8qKo7qp6oaiHwYGgiGdOA1s2A92+FLqfA+X+3YaImKgVbCKpbr64nmo1pHKqGiTbvBJe/CnF2gaCJTsEWgmwR+auIdPN+/grMCWUwY0JqTwG8dhmgcPVbkNzS70TG+CbYQnAHUAq8AbwOFAO3hSqUMSFVXgpvXguF6+GK16CVTRZooluwo4Z2A/eHOIsxoacKH94Na7+Ei56FLif7ncgY3wU7augzEWkR8DxNRD4JXSxjQmTBBJg3Dk77OfS73O80xjQKwXYNpXsjhQBQ1e0EcWWxiIwUkWUislJEDmlRiMjjIjLP+1kuIoXVbceYerFzE0y6FzoOhuHWwDWmSrAjfypFpLOqrgcQkQyqmY00kHeLy6eA7wG5wGwRmaiqi6vWUdV7Ata/AxhwROmNCZYqfHAXlBfDhf+CmFi/ExnTaARbCH4FfCUi0wEBTgXGHuY9Q4CVqroaQEReB0YDi2tY/0rs2gQTKvPGwYpP4PuPQnp3v9MY06gE1TWkqh8DWcAyYDzwU2BvrW+CDkBOwPNc77VDiEgXIBP4vIblY0UkW0Sy8/Pzg4lszH47cuHjX7iLxobe7HcaYxqdYCed+zFwF9ARmAecCMzgwFtXHo0rgAmqWlHdQlV9FngWICsrq9YuKWMOoArv3w6VFTD6KYix+00Yc7Bg/yruAgYD61T1DFxf/uFO7G4AOgU87+i9Vp0rcC0NY+pX9guweiqc/TC0zPQ7jTGNUrCFoFhViwFEJFFVlwI9D/Oe2UB3EckUkQTczn7iwSuJSC8gDdfCMKb+FKyBT38DXYdD1g1+pzGm0Qr2ZHGudx3Be8BnIrIdWFfbG1S1XERuBz4BYoEXVHWRiDwMZKtqVVG4AnhdVa3Lx9SfykrXJRQTCxf8wyaTM6YWwV5ZfJH38CERmQo0Bz4O4n2TgEkHvfbAQc8fCiqpMUdi1jOw7itXBFp0Ovz6xkSxI55BVFWnhyKIMfVm60qY/FvofjYMuMbvNMY0ejaEwkSWygp47xY3pfT5T1iXkDFBsHsKmMjy9ZOQOwsufg6atfc7jTFhwVoEJnJsWeJuOdnrPDj+Ur/TGBM2rBCYyFBRBu/eDImpcN7frEvImCNgXUMmMnz1OGyaB5e+DCmt/U5jTFixFoEJf5u+g+l/hL6XQJ8L/U5jTNixQmDCW3mpGyWU3ApG/dnvNMaEJesaMuFt+h9h80K48nW7Ab0xdWQtAhO+Nsxx5wb6XQU9z/E7jTFhywqBCU9lxfDuLZDSFkY+6ncaY8KadQ2Z8DT1Edi6DK55G5q08DuNMWHNWgQm/KyfCV//AwZdB8eO8DuNMWHPCoEJL6V73CihFp3g7Ef8TmNMRLCuIRNepvwWClbBDz9wVxEbY46atQhM+FjzJcx8GobcBJmn+Z3GmIhhhcCEh5IieP9WaNkVRjzodxpjIop1DZnw8OlvoDAHrv8YEpr6ncaYiGItAtP4rZwCc16Ek26Dzif6ncaYiGOFwDRuewth4h2Q3gPO/LXfaYyJSNY1ZBq3T34JRZvghskQ38TvNMZEJGsRmMZr2ccwbxwMuwc6DvI7jTERywqBaZzKimHSvdCmN5x+n99pjIlo1jV0tJZ8CKW7od/lfieJLNn/hh05MOY9iEv0O40xEc0KwdEo2+tOZJbugi4nQYvOfieKDMU74Is/Q9fh0O0Mv9MYE/Gsa+hoLJgAewugshym/sHvNJHj6yfd73XEQ34nMSYqWCGoK1WY9Yzrwz7pNpj/Omxe5Heq8Fe0GWY8BX0ugmMG+J3GmKhghaCu1s+AvAUwZCwM+wkkNoMpD/udKvx98SeoKIUzf+N3EmOihhWCupr5DCS1gBMuc/fKHXYXLP8Y1s3wO1n4KljtriAeeC206uZ3GmOihhWCutiRC0s+gIFj9s97M/QWSGkHkx903UbmyH3+e4hNsOGixjSwkBYCERkpIstEZKWI3F/DOpeJyGIRWSQir4UyT73JfgFQGHzj/tcSkmH4fZAzE5Z95Fu0Wm1dAS9f0DjPZWyaDwsnwIm3QGo7v9MYE1VCVghEJBZ4CjgH6A1cKSK9D1qnO/AL4BRV7QPcHao89aasGOa8BD3OgbQuBy4bMAZadnPnCiorfIlXo8pKeP82WDMd3hkL5aV+JzrQ5N9CkzQ45S6/kxgTdULZIhgCrFTV1apaCrwOjD5onRuBp1R1O4Cqbglhnvqx8G3Ysw2G3nTosth4OOs3kL8Evnuj4bPVJvvfrrXS70rYvBC++D+/E+235gtYNQVO/SkkNfc7jTFRJ5SFoAOQE/A813stUA+gh4j8T0S+EZGR1W1IRMaKSLaIZOfn54cobhBU3R2yWh9X8x2yel/ohj1O/YNrPTQGO3Jh8kPQ7Uy48F/Q7yr48q+wYY7fydzvdPJD0KzjgV1txpgG4/fJ4jigOzAcuBJ4TkRaHLySqj6rqlmqmtW6desGjhggZybkfQdDx4JI9euIuAuhduS4o3C/qcJ/fwpaCec97vKNfBRS2sK7t/hfrJZMdAXpjF9AfJK/WYyJUqEsBBuATgHPO3qvBcoFJqpqmaquAZbjCkPjNPNp13VxwmHmFeo6HLqe4aZJKN7REMlqtvBtN6z1zF9DWoZ7rUkLGP0kbF0GU3/vX7aKcpjyO2jdy3VZGWN8EcpCMBvoLiKZIpIAXAFMPGid93CtAUQkHddVtDqEmepuxwZYPNGdEA7mVokjHnLTJHz9ZKiT1WxPAXx0HxwzEIbefOCyY0fAoOtcvvUzfYnHvFdh2wp38VhMrD8ZjDGhKwSqWg7cDnwCLAHeVNVFIvKwiFzgrfYJsE1EFgNTgZ+p6rZQZToq2S+47pUhQfZjH9Mf+lzspkso2hzabDX55FdQXAgXPFn9jvbsR6BFJ3jvFijd07DZSvfAtMeg4xDodW7DfrYx5gAhPUegqpNUtYeqdlPV33uvPaCqE73Hqqo/UdXeqnq8qr4eyjx1Vlbsrnjtec7+7pVgnPlrN12CHyN0Vk6B+a/BKXdDu77Vr5OYCqOfgoJVMOW3DZtv1jPuzmMjHqr5fIsxpkH4fbI4PCx6p+Yho7Vp1c1NlzDnJdi2KiTRqlW6Gz68G1p1h9N+Vvu6mafBkJvc+Y81XzZMvr3b4avHofvZkHFKw3ymMaZGVggOZ9+Q0V6QefqRv//0+9y0CQ15UnbqH6BwPVzwRHAjcUY8CC27wvu3QklR6PN99TgU74SzHgz9ZxljDssKweHkzHLTHwypZchobVLbuWkTFr4NG+fVf76DbZgD3/wTsq6HLicH956Epu76gsIc+DTEs37u3Ogm7Dvhspq7rIwxDcoKweHMfBoSgxgyWptT7nLTJ4S6H76iDN6/w10jMOKhI3tv5xPdfRXmvOjOL4TKtMfc9Btn/DJ0n2GMOSJWCGqzc6O74GngGEhMqft2kpq76RNWfQ6rp9dfvoP97++wZRGc+5e6TdVw5q8hvYe7/ebewvrPt3UFfPsqDL7hyE66G2NCygpBbbJfcEevg3989NsafKObRmHyQ6GZpnrrCpj+f26Ki7oOx4xvAhc+7UbzfBKCI/YpD7vPOPXe+t+2MabOrBDUpLwEsl+EHiOhZebRby8+yU2jsHGua2XUp8pKmHin+4xzjnKoasdBMOwemDcOln1cP/kAcue4733yHZDi4zQhxphDWCGoycJ3YM9WN69Qfel3pRt9NOV3bnqF+jL3JVj/NZz9e0hte/TbO/0+aNMHPrjTXZ18tFTdDXuS0915CGNMo2KFoDpVQ0bTe7o5g+pLTCyc9YCbVmHeq/WzzZ0b4bMH3fUAA66pn23GJcJFT7trJyYd5jqEYKyaAmu/hNN/7i5iM8Y0KlYIqpM7GzbNq32W0brqOQo6DXWjZ452WoeqmUUrSuH8v9dv1vYnwGk/d3cNW/x+3bdTWenOi7ToAoN+VG/xjDH1xwpBdWY+4w0ZvaL+t101TXXRJjfNwtFY/D4sm+SGYrbsWh/pDnTqT6B9f/jwJ7B7a922segdyFvgRiTFJdRvPmNMvbBCcLCdm2Dxe66b5WiGjNamy8nQ/fvuCtu92+u2jT0FrtumfT84MUT97rHxrouoZCd8eM+Rj3YqL4XPfwdtj4e+PwhNRmPMUbNCcLA5L7oho0PqYchobc56wE2z8NXjdXv/Z79xffgXPAmxcfWbLVCb41yLY8lEd3X0kZj7Mmxf66awiLF/asY0VvbXGai8xF070OP7oelqCdSur5tmYeYz7l4HR2L1NHdh1sl3uBZBqJ18J3Qc7M5HFOUF956SXTD9j9DlFHfvA2NMo2WFINCid2F3vptXqCGc8UvX+pj+WPDvKd0DH9zlCtXw+0OXLVBMrJuLqLzYfXYwXUTf/NP9Lkf81qaZNqaRs0JQZd+Q0R7uJu8NIS3DTbfw7auQvzy490x71HW3nP93d5VuQ0nv7mYLXf4xzHut9nV3b4X/PQG9zoNOgxsmnzGmzqwQVMnNho3f1n2W0bo69V6IT4bPHz78uhvnwYx/uHscZJ4W+mwHG3qz6+r5+H7YkVvzel/+Fcp2u/MgxphGzwpBlVnPQGIz6BeCIaO1SWnt+vqXfOCKUU0qymDi7dC0NXwviKIRCjEx7o5mlRVuYrrquogK18Ps56D/VdC6Z8NnNMYcMSsE4E6ALnoX+l/tz5WvJ93mpl+obUK6Gf9w4/FH/dlNae2Xlplw9sNuJtU5Lx66fOqjgMDwXzR4NGNM3VghADe5XGVF8Demr2+JqW76hbVfuukYDrZtlbsSudd50PuChs93sKwboOtw+OTX7nxFlc2LYf54d0V2844+hTPGHCkrBOWlbsho97PdPYb9MuhHbhqGyQ+5aRmqqLqROrGJrjXQGIjABf9wo4neu21/3ikPu+61YT/xN58x5ohYIVj8HuzeUr+zjNZFXIKbhiFvgZuWocrcV1xL4eyHoVl7//IdrEUn+P4fYN1XMOtZWDcDln8Ew+6C5JZ+pzPGHAErBDOfhlbdoWsDDRmtTd8fuOkYPv+da6kU5bl7CHcZBgOu9TvdoQZc41pSkx+CSfdCSjsYeovfqYwxRyi6C0FutrvZ+5CxjWMKhJgYNx3D9rVueoZJ97qLuM7/e+PIdzAROP8J15rZvBCG3wcJyX6nMsYcoRBOUhMGZj4DCanQ/0q/k+x37AjXAvjsASjb4y7iSj/W71Q1a9YeLn7ejboaMMbvNMaYOmiEh5kNpGizt/PyachoTaqmqS7b47qJTr7D70SH1+NsuOhfbrZSY0zYid4WwZwXobKs4eYVOhKdBsMVr0G7E2znaowJuegsBFVDRo/9nr9DRmvT61y/ExhjokR0dg0tfh92bXZz5xhjTJSLzkIw82lo2a3hZhk1xphGLKSFQERGisgyEVkpIodMni8i14lIvojM835CfFswIHcObMiGoTc1ziGZxhjTwEJ2jkBEYoGngO8BucBsEZmoqosPWvUNVb09VDkOMesZSEiBfo1oyKgxxvgolIfEQ4CVqrpaVUuB14HRIfy8wyvaDAvfcbOMJjXzNYoxxjQWoSwEHYCcgOe53msHu0REvhORCSLSqboNichYEckWkez8/Py6J5rzUuMdMmqMMT7xu5P8AyBDVU8APgNerm4lVX1WVbNUNat169Z1+6R9Q0ZHNO4rdY0xpoGFshBsAAKP8Dt6r+2jqttUtcR7+jwwKGRplkyEXXk2ZNQYYw4SykIwG+guIpkikgBcAUwMXEFEAudVvgBYErI0CSnQ81zodlbIPsIYY8JRyEYNqWq5iNwOfALEAi+o6iIReRjIVtWJwJ0icgFQDhQA14UqDz1Huh9jjDEHEK3pHrmNVFZWlmZn13KTd2OMMYcQkTmqmlXdMr9PFhtjjPGZFQJjjIlyVgiMMSbKWSEwxpgoZ4XAGGOinBUCY4yJclYIjDEmyoXddQQikg+sq+Pb04Gt9Rgn1MIpbzhlhfDKG05ZIbzyhlNWOLq8XVS12snawq4QHA0Rya7pgorGKJzyhlNWCK+84ZQVwitvOGWF0OW1riFjjIlyVgiMMSbKRVsheNbvAEconPKGU1YIr7zhlBXCK284ZYUQ5Y2qcwTGGGMOFW0tAmOMMQexQmCMMVEuagqBiIwUkWUislJE7vc7T01EpJOITBWRxSKySETu8jtTMEQkVkS+FZEP/c5SGxFpISITRGSpiCwRkZP8zlQbEbnH+3ewUETGi0iS35kCicgLIrJFRBYGvNZSRD4TkRXef9P8zFilhqx/8v4tfCci74pICz8zVqkua8Cyn4qIikh6fX1eVBQCEYkFngLOAXoDV4pIb39T1agc+Kmq9gZOBG5rxFkD3UUobzVaf/4OfKyqvYB+NOLMItIBuBPIUtW+uDv9XeFvqkO8BBx867/7gSmq2h2Y4j1vDF7i0KyfAX1V9QRgOfCLhg5Vg5c4NCsi0gk4G1hfnx8WFYUAGAKsVNXVqloKvA6M9jlTtVR1k6rO9R4X4XZUHfxNVTsR6QicCzzvd5baiEhz4DTg3wCqWqqqhf6mOqw4oImIxAHJwEaf8xxAVb/A3WY20GjgZe/xy8CFDRqqBtVlVdVPVbXce/oN0LHBg1Wjht8rwOPAz4F6HeUTLYWgA5AT8DyXRr5zBRCRDGAAMNPfJIf1N9w/zkq/gxxGJpAPvOh1Yz0vIk39DlUTVd0A/Bl39LcJ2KGqn/qbKihtVXWT9zgPaOtnmCNwPfCR3yFqIiKjgQ2qOr++tx0thSDsiEgK8DZwt6ru9DtPTUTkPGCLqs7xO0sQ4oCBwL9UdQCwm8bTbXEIr299NK6AHQM0FZFr/E11ZNSNT2/0Y9RF5Fe4btlxfmepjogkA78EHgjF9qOlEGwAOgU87+i91iiJSDyuCIxT1Xf8znMYpwAXiMhaXJfbmSLyqr+RapQL5KpqVQtrAq4wNFYjgDWqmq+qZcA7wMk+ZwrGZhFpD+D9d4vPeWolItcB5wFXa+O9sKob7oBgvve31hGYKyLt6mPj0VIIZgPdRSRTRBJwJ9wm+pypWiIiuD7sJar6V7/zHI6q/kJVO6pqBu73+rmqNsqjVlXNA3JEpKf30lnAYh8jHc564EQRSfb+XZxFIz65HWAi8EPv8Q+B933MUisRGYnr1rxAVff4nacmqrpAVduoaob3t5YLDPT+TR+1qCgE3smg24FPcH9Ib6rqIn9T1egUYAzuyHqe9zPK71AR5A5gnIh8B/QH/uBznhp5LZcJwFxgAe7vtVFNiSAi44EZQE8RyRWRG4DHgO+JyApcq+YxPzNWqSHrP4BU4DPvb+1pX0N6asgaus9rvC0hY4wxDSEqWgTGGGNqZoXAGGOinBUCY4yJclYIjDEmylkhMMaYKGeFwJgGJCLDG/sMrSb6WCEwxpgoZ4XAmGqIyDUiMsu7yOgZ734Lu0Tkce/+AFNEpLW3bn8R+SZgTvs07/VjRWSyiMwXkbki0s3bfErAPRHGeVcNG+MbKwTGHEREjgMuB05R1f5ABXA10BTIVtU+wHTgQe8trwD3eXPaLwh4fRzwlKr2w80RVDUj5wDgbty9MbririY3xjdxfgcwphE6CxgEzPYO1pvgJk6rBN7w1nkVeMe7x0ELVZ3uvf4y8JaIpAIdVPVdAFUtBvC2N0tVc73n84AM4KvQfy1jqmeFwJhDCfCyqh5wtyoR+c1B69V1fpaSgMcV2N+h8Zl1DRlzqCnAD0SkDey7B28X3N/LD7x1rgK+UtUdwHYROdV7fQww3bu7XK6IXOhtI9GbU96YRseORIw5iKouFpFfA5+KSAxQBtyGu5HNEG/ZFtx5BHBTLT/t7ehXAz/yXh8DPCMiD3vbuLQBv4YxQbPZR40JkojsUtUUv3MYU9+sa8gYY6KctQiMMSbKWYvAGGOinBUCY4yJclYIjDEmylkhMMaYKGeFwBhjotz/A0IBXawA4yKkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(csv['accuracy'])\n",
    "plt.plot(csv['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "9YdWtbaFVpW8",
    "outputId": "36e3d6e5-5d2b-4f81-84dc-f5b3a34f9206"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(csv['loss'])\n",
    "plt.plot(csv['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1uTQdJOvVpW8"
   },
   "source": [
    "## Q: Plotting Predictions\n",
    "Plot some of model predictions with true labels. Share your insights\n",
    "### Your Answer:\n",
    "The model is misclassifying on the basis of contrast and some veins-like branches. Some of the labels look incorrect to the untutored eye as well, where I think the model is picking well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tvtryuqrVpW9"
   },
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join(str(data_path), 'Best_Good_Bad_Quality_Image_Weights.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iqOM9DWYF-Xd"
   },
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "for idx in range(len(X_val)):\n",
    "    x=cv2.imread(str(image_path)+'/'+X_val[idx])\n",
    "    x=cv2.resize(x, (224,224))\n",
    "    op=model.predict(np.expand_dims(img_standardization(x), axis=0),verbose=1)\n",
    "    y_pred.append(op)\n",
    "    print (index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "9S5mfFoCHDz6"
   },
   "outputs": [],
   "source": [
    "prediction_y=[]\n",
    "\n",
    "for i in y_pred:\n",
    "  if i[0][0]>0.5:\n",
    "    prediction_y.append(0)\n",
    "  else:\n",
    "    prediction_y.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nrwEihFHVpW9",
    "outputId": "be35d5fa-dfbd-423c-dda3-09c6ff87783b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.77      0.80       100\n",
      "           1       0.79      0.84      0.81       100\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.81      0.80      0.80       200\n",
      "weighted avg       0.81      0.81      0.80       200\n",
      "\n",
      "[[77 23]\n",
      " [16 84]]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "print(metrics.classification_report(Y_val, prediction_y))\n",
    "print(metrics.confusion_matrix(Y_val, prediction_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JbkOyltDBR4Q"
   },
   "outputs": [],
   "source": [
    "for idx, row in enumerate(Y_val):\n",
    "  if row==prediction_y[idx]:\n",
    "    plot_image(str(image_path)+'/'+X_val[idx], label=row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rjGLvro3BYML"
   },
   "outputs": [],
   "source": [
    "for idx, row in enumerate(Y_val):\n",
    "  if row!=prediction_y[idx]:\n",
    "    plot_image(str(image_path)+'/'+X_val[idx], label=row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1x1_XlcVpW-"
   },
   "source": [
    "## Q: Improvements\n",
    "- Is your model making any obvious errors? \n",
    "- Compare the results of the CNN model with the simple model you trained earlier. Comment on the outcome of this comparison.\n",
    "\n",
    "### Your Answer:\n",
    "\n",
    "1. With the limited understanding of subject matter that I have, I think the model is confused with brightness majorly. Any bright spots on the image, it marks it as a good quality image. Probably misclassified images can oversampled or augmented and the model can be trained. Another way to approach this would be figure out the misclassified samples in the training set and finetune the last few layers of the model on them with a lower learning rate. I also think the labels in the image are a bit subjective and images which are a bit on the bad side have been classified as good.\n",
    "\n",
    "2. The results in both the models is not much different. Class 0 has 3% less recall in CNN and Class 1 has 6% less recall. Now the thing is statistically these results are not that significant because the simple model had just 60 images in the validation set and here we have more than thrice of them. A model comparison would be ideal on the same evaluation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7X_qxRnvVpW-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LO__WX6OVpW-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FOtZngCqVpW_"
   },
   "source": [
    "# Step 3: Multi-level Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kz9w7rfVVpW_"
   },
   "source": [
    "In this stage, consider building a model to predict the image quality with multiple class labels: good, accept and bad. You are not expected to provide code or achieve perfection! Rather, we would like to at least see in writing what next steps you think are useful and why. Specifically, try to address:\n",
    "- What methods you would implement from a model and/or data preprocessing standpoint\n",
    "- What challenges you foresee in implementing your selected model and/or data preprocessing approach\n",
    "- How you would evaluate a model that predicts these 3-class labels against the previous models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3YzcBT0JVpXA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. I think if there\\'s a clear definition and labels for what \"accept\" images are, I\\'ll stick to DenseNet-121 for classification. Else, with some help from medical professionals, one could bucket the current binary classification\\nmodel on the basis of thresholds in three different bins. Also, I think using photometric augmentations would help as currently the model is misclassifying images with low brightness\\n\\n2. Challenges could include interclass misclassification at all the three levels, because when it comes medical images, I think annotating or labeling them involves subjectivity at some point. For example, if the same X-ray is\\nshown to two radiologists for quality, it is  likely in the extreme case that both have different opinions on the quality. In my experience, this problem is difficult to solve. Since, the model can only be as good as the data. So, I foresee\\ndata annotation and misclassification challenges consequently\\n\\n3. At an individual class level, I think F-1 score would be a good metric. Another thing would be see the number of cases that are acceptable or good and classified as bad or vica versa. On the other hand,\\nI think the accept class can be seen combined as a part of the good class in a strategic way (weighted averaging) when comparing against the bad quality images.\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1. I think if there's a clear definition and labels for what \"accept\" images are, I'll stick to DenseNet-121 for classification. Else, with some help from medical professionals, one could bucket the current binary classification\n",
    "model on the basis of thresholds in three different bins. Also, I think using photometric augmentations would help as currently the model is misclassifying images with low brightness\n",
    "\n",
    "2. Challenges could include interclass misclassification at all the three levels, because when it comes medical images, I think annotating or labeling them involves subjectivity at some point. For example, if the same X-ray is\n",
    "shown to two radiologists for quality, it is  likely in the extreme case that both have different opinions on the quality. In my experience, this problem is difficult to solve. Since, the model can only be as good as the data. So, I foresee\n",
    "data annotation and misclassification challenges consequently\n",
    "\n",
    "3. At an individual class level, I think F-1 score would be a good metric. Another thing would be see the number of cases that are acceptable or good and classified as bad or vica versa. On the other hand,\n",
    "I think the accept class can be seen combined as a part of the good class in a strategic way (weighted averaging) when comparing against the bad quality images.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kSKkH8isVpXA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tz0A2w_EVpXA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Rvw3HWsVpXA"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XgYofNSDVpXA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9raeNgl4VpXB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hL5eovVQVpXB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F-kNoBS5VpXB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-xEdQ72VpXB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Tesseract ML Challenge .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
